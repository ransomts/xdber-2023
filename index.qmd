---
title: "Topic modeling Communities of Practice to Identify Learning Barriers"
subtitle: "X-DBER 2023"
author: "Tim Ransom"
email: "tsranso@clemson.edu"
bibliography: references.bib
csl: ieee.csl
html:
  anchor-sections: true
  default-image-extension: svg
  
format:
  revealjs:
    embed-resources: false
    navigation-mode: grid
    transition: slide
    menu:
      side: left
      width: wide
    logo: figures/Clemson_logo.png
    css: logo.css
    theme: serif
    footer: "Subreddit Topic Modeling"
---

## who I am

```{r setup, include=FALSE}
library(pak)
library(languageserver)
library(markdown)
library(tidyverse)
library(magrittr)
library(qrcode)
library(VennDiagram)
library(ggpubr)
library(ggiraph)
library(ggvenn)
library(ggwordcloud)
library(ggvenn)
library(svglite)


knitr::opts_chunk$set(cache = TRUE)

make_interactive_graph <- function(data_filename, title, number_cols = 3) {
  graph <- read_rds(data_filename) %>%
    group_by(topic) %>%
    top_n(7, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>%
    mutate(term = reorder(term, beta)) %>%
    ggplot(mapping = aes(x = beta, y = term, fill = factor(topic))) +
    ggtitle(title) +
    geom_col_interactive(
      show.legend = FALSE,
      aes(tooltip = sprintf("%s: %.0f", term, beta))) + 
    facet_wrap_interactive(vars(topic), scale = "free", ncol = number_cols)
  return(graph)
}

make_wordcloud <- function(data_filename, title, number_cols = 2) {
  plot <- read_rds(data_filename) %>% 
    group_by(topic) %>%
    top_n(30, beta) %>%
    ungroup() %>% 
    ggplot(aes(label = term, size = beta)) +
    geom_text_wordcloud_area(rm_outside = TRUE) +
    scale_size_area(max_size = 35) +
    theme_minimal() +
    ggtitle(title) +
    facet_wrap(~topic, ncol = number_cols)

  return(plot)
}

```

<!-- 
# abstract

Programmers and programming students often find support and community through online spaces. Reddit in particular has a large number of active users participating in online communities of practice for programming and learning to program. Topics being discussed in these two spaces provide a rich data source to address the research question: How can we identify topics of discussion for learning through online communities?

In this work I showcase an established natural language topic modeling algorithm (latent drilect allocation, LDA) to compare the topics of discussion between a community of practice and another community intended for learning that practice. Cross community comparisons and intra community historical trends both contribute to an understanding of what practitioners consider important for learning the practice, learners ponts of struggle, and data indicating evolutions of the practice over time.

I investigate the communities r/Python and r/learnpython for this work. Both are highly active (approx. 1.1 million and 648 thousand members respectively) spaces focused on the practice and learning of the Python programming language. This language is quickly becoming the most popular tool of choice for introductory computing courses and so warrants educational analysis from as many data sources as possible.

This methodology of community comparison is easily extended into other domains with online communities. For example on Reddit there are dual communites for math (r/math & r/learnmath), engineering (r/engineering & r/EngineeringStudents), physics (r/Physics & r/learnPhysics), and several other STEM disciplines.
-->

::: {.columns}
:::: {.column width="45%"}

- Computer Scientist
- Mathematician
- English Speaker
- Clemson ESED graduate Student
- Cat person

::::
::: {.column width="25%"}
![](figures/tim-headshot.jpg){width=60%, fig-alt="photograph of Tim"}
:::

:::: {.column width="25%"} 
:::: {.fragment .fade-in fragment-index=2}
![](figures/ada.jpg){width=60%, fig-alt="Tim's cat Ada"}
::::
::::

:::


::: {.notes}
I am the greatest
:::

## Uses of NLP scraping in classrooms

 - determine which topics students are asking for help online
   - (assumption) highly requested help topics indicate difficult to learn topics
 - determine which topics students can find answers for online
   - (assumption) students are searching for help on Reddit
 - determine which topics students might be most exposed to online
 - identifying barriers to learning
 
## What is Reddit

![](figures/Reddit_Mark_OnWhite.svg){.absolute top=0 right=0 width=200}

 - BBS-system pseudo-anonymous social media
   - (Basically image/text forums with accounts)
 - Organized into subreddits around topics
 <!-- - Topics range from memes to STEM disciplines -->

::: {.fragment}
| Community     | Learning Community    |
|---------------+-----------------------|
| r/Python      | r/learnpython         |
| r/math        | r/learnmath           |
| r/engineering | r/EngineeringStudents |
| r/Physics     | r/learnPhysics        |
:::

## Conceptualizing subreddits as communities of practice [@lave1991situating]

 - people → subscribed users
 - practice → topic of the subreddit
 - culture → layered internet & domain

::: {.fragment}
![](figures/example-reddit-post.png)
:::

::: {.notes}
Communities of practice are to help communicate with education researchers

Screenshot is to illustrate the online culture layered with computing culture
:::

## Latent Drilicht Allocation

- LDA [@blei2003latent] is a well established NLP topic modelling algorithm
- Documents are comprised of a mixture of terms and topics
- With sufficiently many documents we can correlate the relationship between terms and topics

 We'll be topic modelling Reddit post data collected through pushshift [@baumgartner2020pushshift]

## Illuminatory Example

```{r}
knitr::include_graphics("figures/blei-2003-example-lda.png")
```


## Subreddit CoP Topics can Overlap

```{r}

data <- list(`r/python` = c("code", "python", "function"),
          `r/learnpython` = c("help", "how to", "want", "python"))
venn <- ggvenn(data, c("r/python", "r/learnpython"), show_elements = TRUE, label_sep = "\n\n", fill_color = c("#F56600", "#522D80"))

ggsave(filename = "figures/subreddit_venn.svg", plot = venn)

knitr::include_graphics("figures/subreddit_venn.svg")
```

## Python wordclouds

::: {.columns}

:::: {.column width="45%"}

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-Python-2017-6.rds",
  title = "r/python 2017 topics",
  number_cols = 1),
  height_svg = 12)
```


::::

:::: {.column width="45%"}
```{r}
wordcloud_plot <- make_wordcloud(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-Python-2017-6.rds",
  title = "r/python 2017 topic wordclouds", 
  number_cols = 2)

ggsave(plot = wordcloud_plot,
       filename = paste0("figures/python-2017-wordcloud.svg"),
       height = 12, units = "in")

knitr::include_graphics(path = "figures/python-2017-wordcloud.svg")
```

::::

:::

## learnpython wordclouds

::: {.columns}

:::: {.column width="45%"}

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-learnpython-2017-6.rds",
  title = "r/learnpython 2017 topics",
  number_cols = 1),
  height_svg = 12)
```


::::

:::: {.column width="45%"}
```{r}
wordcloud_plot <- make_wordcloud(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-learnpython-2017-6.rds",
  title = "r/learnpython 2017 topic wordclouds", 
  number_cols = 2)

ggsave(plot = wordcloud_plot,
       filename = paste0("figures/learnpython-2017-wordcloud.svg"),
       height = 12, units = "in")

knitr::include_graphics(path = "figures/learnpython-2017-wordcloud.svg")
```

::::

:::

## ojs test {background-iframe="https://ransomts.github.io/xdber-2023/observable.html" background-interactive=true}

## Single Subreddit Topics

::: {.columns}

:::: {.column width="45%"}
r/python

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-Python-2017-6.rds",
  title = "r/python 2017 topics",
  number_cols = 1),
  height_svg = 12)
```

::::

:::: {.column width="45%"}
r/learnpython

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-learnpython-2017-6.rds",
  title = "r/learnpython 2017 topics",
  number_cols = 1),
  height_svg = 12)
```

::::

:::

## r/learnpython over time

::: {.panel-tabset}

### 2014

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-learnpython-2014-6.rds",
  title = "r/learnpython 2014 topics"))
```

### 2015

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-learnpython-2015-6.rds",
  title = "r/learnpython 2015 topics"))
```

### 2016

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-learnpython-2016-6.rds",
  title = "r/learnpython 2016 topics"))
```

### 2017

```{r}
girafe(ggobj = make_interactive_graph(
  data_filename = "/home/tsranso/Code/reddit-analysis/data/lda-learnpython-2017-6.rds",
  title = "r/learnpython 2017 topics"))
```

:::

## Identified Learning Barriers



## Next Steps

- Interpret other subreddits
- Interpret other disciplines

## References {.unnumbered}

::: {#refs}
:::

## Contact info

email:
tsranso@clemson.edu

github:
[https://github.com/ransomts](https://github.com/ransomts)

website:
[tsranso.people.clemson.edu](tsranso.people.clemson.edu)
{{< qrcode https://tsranso.people.clemson.edu qr1 width=100 height=100 >}}
